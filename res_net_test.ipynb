{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-vAzMtYS1IVN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "unbPREkJ1JPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "WUVgqvIoMnSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNQKSaJsML9m"
      },
      "outputs": [],
      "source": [
        "# google 掛載點位\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') # 就是掛在這邊~"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/gdrive/MyDrive/ColabNotebooks\"\n",
        "# should colab.zip is exists."
      ],
      "metadata": {
        "id": "pPXnExBAMq1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/gdrive/MyDrive/ColabNotebooks/* ./\n",
        "# !ls"
      ],
      "metadata": {
        "id": "YjDYfV0J1fvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and copy some file from GD, like pt, or txt.\n",
        "# !cp /content/gdrive/MyDrive/ColabNotebooks/1222_0009_08_e1500.pt ./\n",
        "# !cp /content/gdrive/MyDrive/ColabNotebooks/loss_recoder_1221_1753_08.txt ./\n",
        "# !ls"
      ],
      "metadata": {
        "id": "9_lJhIht67dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/gdrive/MyDrive/ColabNotebooks/colab.zip -d ./"
      ],
      "metadata": {
        "id": "gwxULUj4MvBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls\n",
        "\"\"\" should list this files.\n",
        "1221_0909_30_e999.pt   dataloader.py\t model.py\t     train_local.ipynb\n",
        "1221_1602_00_e1999.pt  gdrive\t\t rebuild_test.ipynb  train.py\n",
        "after.png\t       __init__.py\t res_AE.py\t     unet\n",
        "before.png\t       loss_recoder.png  res_unet\t     Untitled.ipynb\n",
        "data\t\t       lr_recoder.png\t sample_data\t     util.py\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rCngtyX1NHg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VRY9ZJNANRr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import model as my_model\n",
        "import dataloader as my_dataset\n",
        "import train as my_train\n",
        "from res_AE import ResNetAE  # res_ae = ResNetAE()\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn as nn\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "pq2yCgvmNY9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveBestModel:\n",
        "    \"\"\"\n",
        "    Class to save the best model while training. If the current epoch's\n",
        "    validation loss is less than the previous least less, then save the\n",
        "    model state.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self, save_root, best_valid_loss=float('inf')\n",
        "    ):\n",
        "        self.save_path = save_root\n",
        "        ensure_dir(self.save_path)\n",
        "        self.best_valid_loss = best_valid_loss\n",
        "\n",
        "    def __call__(\n",
        "            self, current_valid_loss, net, current_epoch,\n",
        "    ):\n",
        "        if current_valid_loss < self.best_valid_loss:\n",
        "            self.best_valid_loss = current_valid_loss\n",
        "            print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
        "            print(f\"Saving best model for epoch: {current_epoch}\\n\")\n",
        "            _file_name = Path(self.save_path).joinpath(\"best.pt\")\n",
        "            torch.save(net.state_dict(), _file_name)\n",
        "            # for colab special command\n",
        "            !cp /content/$_file_name /content/gdrive/MyDrive/ColabNotebooks/$_file_name\n",
        "            return True\n",
        "        else:\n",
        "            return False"
      ],
      "metadata": {
        "id": "4aNQHbY3w3iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "good_bad_dataset = my_dataset.QR_good_bad_dataset(\"./data\", image_size=256, image_channels=1)\n",
        "\n",
        "# split dataset\n",
        "#my_dataloader, my_val_dataset = random_split(good_bad_dataset, [0.7, 0.3])\n",
        "my_dataloader, my_val_dataset, my_test_dataset = random_split(good_bad_dataset, [0.7, 0.2, 0.1],\n",
        "                                                              generator=torch.Generator().manual_seed(42))\n",
        "#my_dataloader, my_val_dataset, _ = random_split(good_bad_dataset, [7, 3, 720])  # for fast test\n",
        "\n",
        "# 40GB: 32??\n",
        "running_bs = 32  # batch size\n",
        "my_dataloader = DataLoader(good_bad_dataset, batch_size=running_bs, drop_last=True, \n",
        "                           pin_memory=True, num_workers = 8)\n",
        "my_val_dataloader = DataLoader(my_val_dataset, batch_size=running_bs, drop_last=True, \n",
        "                               pin_memory=True, num_workers = 8)\n",
        "# 繪製 preview 用的大小\n",
        "r, c = 5, 5\n",
        "assert r * c <= len(my_test_dataset)\n",
        "test_dataloader = DataLoader(my_test_dataset, batch_size=r*c, drop_last=False, pin_memory=False)\n",
        "net = ResNetAE(input_shape=(256,256,1))\n",
        "net.cuda()\n",
        "\n",
        "#\n",
        "torch.manual_seed(0)\n",
        "# load model\n",
        "# M_PATH = \"1222_0009_08_e1500.pt\"\n",
        "# net.load_state_dict(torch.load(M_PATH))"
      ],
      "metadata": {
        "id": "aUDHrZL7Y9RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -r Runnings-save_1224_2215_47"
      ],
      "metadata": {
        "id": "rIqNqmTcOefQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 手糙 UTC-8\n",
        "# from datetime import datetime, timedelta\n",
        "# (datetime.now() + timedelta(hours=8)).strftime('%m%d_%H%M_%S')"
      ],
      "metadata": {
        "id": "CYVwCSym5KmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bl4kh0SCOxBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datetime.now()"
      ],
      "metadata": {
        "id": "WzLzNKnuREzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm\n",
        "import model as my_model\n",
        "import dataloader as my_dataset\n",
        "import torch.optim as optim\n",
        "from datetime import datetime, timedelta\n",
        "from torch.utils.data import random_split\n",
        "from  util import ensure_dir\n",
        "from pathlib import Path\n",
        "# param\n",
        "# net = net\n",
        "dataloader=my_dataloader\n",
        "val_dataloader=my_val_dataloader\n",
        "epoches=20000\n",
        "lr=1e-4  ########################################## \n",
        "SAVE_ROUND=50\n",
        "\n",
        "# 時戳\n",
        "current_time = lambda: (datetime.now() + timedelta(hours=8)).strftime('%m%d_%H%M_%S')\n",
        "\n",
        "# 存檔目錄\n",
        "SAVE_ROOT = Path(f\"Runnings-save_{current_time()}\")\n",
        "\n",
        "# for colab special command\n",
        "!mkdir /content/gdrive/MyDrive/ColabNotebooks/$SAVE_ROOT\n",
        "\n",
        "ensure_dir(SAVE_ROOT)\n",
        "_stamp = current_time()\n",
        "LOSS_RECODER_TXT = SAVE_ROOT.joinpath(f\"./loss_recoder_{_stamp}.txt\")\n",
        "with open(LOSS_RECODER_TXT, mode='a', encoding='utf-8') as f:\n",
        "    f.write(f\"=========== Start train: {_stamp} ===========\\n\")\n",
        "    f.write(f\"train loss,\\t valid loss,\\t lr\\n\")\n",
        "\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "assert cuda  # 必須為 == True, cuda 失敗\n",
        "net = net.cuda()\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "# loss function\n",
        "mse = nn.MSELoss()\n",
        "# save 週期\n",
        "save_round = SAVE_ROUND\n",
        "save_cnt = 0\n",
        "#\n",
        "CosineAnnealingWarmRestarts = True\n",
        "if CosineAnnealingWarmRestarts:\n",
        "    alpha_ = epoches / 30  # hyp\n",
        "    the_first_restart = int(epoches * (0.8 / alpha_))  # hyp\n",
        "    T_mult = 2\n",
        "    print(f\"CosineAnnealingWarmRestarts: T_0:{the_first_restart}, T_mult:{T_mult}\")\n",
        "    train_scheduler = optim.lr_scheduler. \\\n",
        "        CosineAnnealingWarmRestarts(optimizer,\n",
        "                                    T_0=the_first_restart,\n",
        "                                    T_mult=T_mult, verbose=False)\n",
        "\n",
        "# best saver\n",
        "save_best = SaveBestModel(SAVE_ROOT)\n",
        "\n",
        "loss_recoder = []\n",
        "loss_val_recoder = []\n",
        "lr_recoder = []\n",
        "pbar = tqdm(range(epoches), smoothing=0.1, ncols=100)\n",
        "for epoch in pbar:\n",
        "    save_cnt += 1\n",
        "    avg_batch_loss = 0\n",
        "    avg_batch_val_loss = 0\n",
        "    for batch_idx, data_good_bad in enumerate(dataloader):\n",
        "        good, bad = data_good_bad\n",
        "        good = good.cuda().float()/255.0\n",
        "        bad = bad.cuda().float()/255.0\n",
        "        bad = Variable(bad)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(bad)\n",
        "        loss = mse(output, good)\n",
        "        avg_batch_loss += loss.detach().cpu().numpy()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if CosineAnnealingWarmRestarts:\n",
        "            train_scheduler.step(epoch + batch_idx / len(dataloader))\n",
        "            lr_recoder.append(train_scheduler.get_last_lr()[0])\n",
        "    # end of dataloader\n",
        "    # calc train loss\n",
        "    __loss = avg_batch_loss / batch_idx\n",
        "    loss_recoder.append(__loss)\n",
        "\n",
        "    # calc val loss\n",
        "    net.eval()\n",
        "    for batch_idx, data_good_bad in enumerate(val_dataloader):\n",
        "        good, bad = data_good_bad\n",
        "        good = good.cuda().float() / 255.0\n",
        "        bad = bad.cuda().float() / 255.0\n",
        "        bad = Variable(bad)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(bad)\n",
        "        loss = mse(output, good)\n",
        "        avg_batch_val_loss += loss.detach().cpu().numpy()\n",
        "    #\n",
        "    __val_loss = avg_batch_val_loss / batch_idx\n",
        "\n",
        "    # save beset weight and preview\n",
        "    if save_best(__val_loss, net, epoch):\n",
        "        plt.style.use('classic')\n",
        "        plt.imshow(my_train.make_test_view(net, test_dataloader,r,c, sub_size=128)*255.0, cmap='gray')\n",
        "        _preview_save = SAVE_ROOT.joinpath(f\"preview_{str(epoch).zfill(5)}.jpg\")\n",
        "        plt.savefig(_preview_save, dpi=300)\n",
        "        !cp /content/$_preview_save /content/gdrive/MyDrive/ColabNotebooks/$_preview_save\n",
        "        plt.clf()\n",
        "        plt.cla()\n",
        "        plt.close(plt.gcf())\n",
        "    #\n",
        "    loss_val_recoder.append(__val_loss)\n",
        "\n",
        "    pbar.set_description(\"Training progress: Epoch{0} loss={1:.6f}, val_loss={2:.6f}\".format(epoch + 1, __loss, __val_loss))\n",
        "    # tranning save\n",
        "    if save_cnt % save_round == 0:\n",
        "        print(\"save model...\")\n",
        "        _pt_name = SAVE_ROOT.joinpath(f'{current_time()}_e{epoch+1}.pt')\n",
        "        torch.save(net.state_dict(), _pt_name)\n",
        "        #  for colab special command\n",
        "        !cp /content/$_pt_name /content/gdrive/MyDrive/ColabNotebooks/$_pt_name\n",
        "    # 紀錄 loss\n",
        "    with open(LOSS_RECODER_TXT, mode='a', encoding='utf-8') as f:\n",
        "        f.write(str(__loss) + \", \" + str(__val_loss) + \", \" + str(train_scheduler.get_last_lr()[0]) + \"\\n\")\n",
        "    # for colab special command\n",
        "    !cp -f /content/$LOSS_RECODER_TXT /content/gdrive/MyDrive/ColabNotebooks/$LOSS_RECODER_TXT  \n",
        "    #--------------------------------\n",
        "    # loss\n",
        "    plt.style.use('ggplot')\n",
        "    fig = plt.figure(\"loss\")\n",
        "    plt.plot(loss_recoder, label='train loss')\n",
        "    plt.plot(loss_val_recoder, label='valid loss')\n",
        "    plt.legend()\n",
        "    plt.yscale('log')\n",
        "    # \n",
        "    loss_recoder_saven = SAVE_ROOT.joinpath(\"loss_recoder.png\")\n",
        "    fig.savefig(loss_recoder_saven, dpi=300)  # colab special\n",
        "    !cp -f /content/$loss_recoder_saven /content/gdrive/MyDrive/ColabNotebooks/$loss_recoder_saven\n",
        "    # lr\n",
        "    fig_lr = plt.figure(\"lr\")\n",
        "    plt.plot(lr_recoder)\n",
        "    plt.yscale('log')\n",
        "    lr_recoder_saven = SAVE_ROOT.joinpath(\"lr_recoder.png\")\n",
        "    fig_lr.savefig(SAVE_ROOT.joinpath(\"lr_recoder.png\"), dpi=300)\n",
        "    !cp -f /content/$lr_recoder_saven /content/gdrive/MyDrive/ColabNotebooks/$lr_recoder_saven\n",
        "    plt.clf()\n",
        "    plt.cla()\n",
        "    plt.close(fig_lr)\n",
        "    plt.close(fig)\n",
        "    plt.style.use('classic')"
      ],
      "metadata": {
        "id": "LnjgVI_ItSHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir mkdir"
      ],
      "metadata": {
        "id": "ZegAeHf_KQIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DJk5XXt8INr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir result"
      ],
      "metadata": {
        "id": "uGDAxROpv18_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test_idx in range(int(730*0.3)):\n",
        "    #test_idx = 100\n",
        "    # bad image\n",
        "    test_batch = my_val_dataset[test_idx][1].reshape(1, 1, 256, 256)\n",
        "    # show bad batch\n",
        "    _test_batch_show = np.array(test_batch.reshape(256, 256))\n",
        "    plt.imshow(_test_batch_show, cmap=plt.cm.gray)\n",
        "    fig1 = plt.gcf()\n",
        "    fig1.savefig(\"before.png\")\n",
        "    net.eval()\n",
        "    output_batch = net(test_batch.cuda().float()/255.0) # / 255.0??\n",
        "\n",
        "    # show output_batch batch\n",
        "    _output_show = output_batch.reshape(256, 256).detach().cpu().numpy()\n",
        "    plt.imshow(_output_show, cmap=plt.cm.gray)\n",
        "    fig2 = plt.gcf()\n",
        "    fig2.savefig(\"after.png\")\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.suptitle('Rebuild')\n",
        "    #\n",
        "    ax1.set_title('before')\n",
        "    ax1.imshow(_test_batch_show, cmap=plt.cm.gray)\n",
        "    #\n",
        "    ax2.set_title('after')\n",
        "    ax2.imshow(_output_show, cmap=plt.cm.gray)\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(f\"./result/rebuild_{test_idx}.png\")\n",
        "    #plt.show()"
      ],
      "metadata": {
        "id": "7UYpQm_WOBak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "loss_fn = \"./loss_recoder_1221_1753_08.txt\"\n",
        "\n",
        "with open(loss_fn, mode='r', encoding='utf-8') as  f:\n",
        "    lines = f.readlines()[2:]\n",
        "\n",
        "tloss_list = []\n",
        "vloss_list = []\n",
        "lr_list = []\n",
        "for line in lines:\n",
        "    tloss, vloss, lr = line.rstrip().split(',')\n",
        "    tloss_list.append(tloss)\n",
        "    vloss_list.append(vloss)\n",
        "    lr_list.append(lr)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "tloss_list = np.array(tloss_list, dtype=np.float64)\n",
        "vloss_list = np.array(vloss_list, dtype=np.float64)\n",
        "lr_list = np.array(lr_list, dtype=np.float64)"
      ],
      "metadata": {
        "id": "ZUpZ3dS9O9Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12,5))\n",
        "\n",
        "ax.plot(tloss_list, label='train loss')\n",
        "ax.plot(vloss_list, label='valid loss')\n",
        "plt.xlabel('epoches', labelpad=10, fontsize=20)\n",
        "plt.ylabel('loss', labelpad=10, fontsize=20)\n",
        "ax.tick_params(axis='y')\n",
        "\n",
        "ax.legend()\n",
        "\n",
        "ax2 = ax.twinx()\n",
        "\n",
        "ax2.plot(lr_list, color='gray', alpha=0.2, label='lr')\n",
        "ax2.tick_params(axis='y', labelcolor='gray')\n",
        "plt.ylabel('lr', labelpad=10, fontsize=20, rotation=0)\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"123.png\", dpi=600)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "0SWmH-BJ_VOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# net = my_train.train(net, my_dataloader, my_val_dataloader, epoches=20000, \\\n",
        "#                      lr=1e-5, SAVE_ROUND=50)"
      ],
      "metadata": {
        "id": "V1-YuxC2ZrE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 打包資料夾，記得左邊把東西先拉到要下的資料夾內\n",
        "!mkdir want_to_download"
      ],
      "metadata": {
        "id": "wclVMHf2qijG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 打包資料夾，記得左邊把東西先拉到要下的資料夾內\n",
        "!zip -r /content/result.zip /content/result\n"
      ],
      "metadata": {
        "id": "xzbjmAqwaViW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 打包東西拉到 GD\n",
        "!cp -f /content/result.zip /content/gdrive/MyDrive/ColabNotebooks/result.zip"
      ],
      "metadata": {
        "id": "m8QDGdrWqzXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OK\n",
        "# _pt_name = \"model.py\"\n",
        "# def abc():\n",
        "#     print('abc')\n",
        "#     !cp /content/$_pt_name /content/gdrive/MyDrive/ColabNotebooks/$_pt_name\n",
        "# abc()"
      ],
      "metadata": {
        "id": "Vk0GoSvqq753"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/XXX.pt /content/gdrive/MyDrive/ColabNotebooks/XXX.pt"
      ],
      "metadata": {
        "id": "P4vfFnuYrYf5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}